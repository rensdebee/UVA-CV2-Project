name: "mvcontrol-sugar"
tag: "${data.random_camera.height}_${rmspace:${basename:${data.image_path}},_}"
exp_root_dir: "workspace/mvcontrol_${system.control_condition_type}"
seed: 0

data_type: "random-camera-sugar-datamodule"
data:
  batch_size: 1
  # 0-4999: 64x64, >=5000: 512x512
  # this drastically reduces VRAM usage as empty space is pruned in early training
  width: 512
  height: ${data.width}
  resolution_milestones: [1000, 2000]
  camera_distance_range: [1.3, 1.5]
  fovy_range: [30, 70]
  elevation_range: [-10, 45]
  # camera_perturb: 0
  # center_perturb: 0
  # up_perturb: 0.
  eval_camera_distance: 1.3
  eval_fovy_deg: 49.1
  eval_elevation_deg: 0
  n_val_views: 8
  # relative_radius: false
  n_predict_views: 800
  predict_height: 512
  predict_width: 512
  predict_azimuth_range: [-180, 180]
  predict_elevation_range: [-10, 80]
  predict_camera_distance_range: [1.3, 1.5]
  rays_d_normalize: false

system_type: "sugar-mvcontrol-system"
system:
  stage: "sugar"
  hint_image_path: ""
  control_condition_type: depth

  postprocess: false

  # ref_camera_ray_noise_scale: [0, 0.002, 0.0001, 2000]
  ref_camera:
    relative_radius: false
    camera_distance: 1.3
    camera_distance_learnable: false
    elevation_learnable: false
    azimuth_learnable: false
    fovy_deg: 49.1
    height: 256
    width: ${system.ref_camera.height}
    resolution_milestones: [1000, 2000]

  geometry_type: "sugar"
  geometry:
    position_lr: [0, 0.00016, 0.0000016, 3000]
    scaling_lr: 0.002
    feature_lr: [0, 0.01, 0.004, 3000]
    opacity_lr: 0.01
    rotation_lr: 0.001

    spatial_extent: ${system.ref_camera.camera_distance}
    spatial_lr_scale: 1

    n_gaussians_per_surface_triangle: 6
    learnable_positions: true
    surface_mesh_to_bind_path: ""

    init_gs_opacity: 0.9

  # renderer_type: "diff-sugar-rasterizer-shading"
  # renderer:
  #   debug: false
  #   # invert_bg_prob: 1.0

  # material_type: "gaussian-diffuse-with-point-light-material"
  # material:
  #   ambient_only_steps: 500
  #   textureless_prob: 0.0
  #   ambient_light_color: [1.0, 1.0, 1.0]
  #   diffuse_light_color: [0.0, 0.0, 0.0]
  #   soft_shading: true

  renderer_type: "diff-sugar-rasterizer-normal"
  renderer:
    debug: false

  material_type: "no-material" # unused
  material:
    n_output_dims: 0

  background_type: "gaussian-mvdream-neural-environment-map-background"
  background:
    color_activation: sigmoid
    random_aug: true
    random_aug_prob: 0.5


  prompt_processor_type: "stable-diffusion-prompt-processor"
  prompt_processor:
    pretrained_model_name_or_path: ${system.guidance.pretrained_model_name_or_path}
    prompt: ???
    negative_prompt: "ugly, bad anatomy, blurry, pixelated obscure, unnatural colors, poor lighting, dull, and unclear, cropped, lowres, low quality, artifacts, duplicate, morbid, mutilated, poorly drawn face, deformed, dehydrated, bad proportions"
    front_threshold: 30.0
    back_threshold: 30.0
    use_perp_neg: false

  guidance_type: "stable-diffusion-vsd-guidance"
  guidance:
    pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base"
    pretrained_model_name_or_path_lora: "stabilityai/stable-diffusion-2-1"
    guidance_scale: 7.5
    min_step_percent: 0.02
    max_step_percent: [500, 0.98, 0.50, 501]
    # grad_clip: 1.0

  freq:
    ref_only_steps: 0
    guidance_eval: 0
    render_normal: 100000
    reset_neighbors: 50

  loggers:
    wandb:
      enable: false
      project: "threestudio"
      name: None

  loss:
    lambda_sds: 0.1
    lambda_sds_control: 0
    lambda_rgb: 0
    lambda_mask: 1000.
    lambda_depth: 0. # 0.05
    lambda_depth_rel: 0.1 # [0, 0, 0.05, 100]
    lambda_normal: 0 # [0, 0, 0.05, 100]
    lambda_normal_smooth: 0
    lambda_3d_normal_smooth: 0
    lambda_normal_consistency: 10.
    lambda_laplacian_smoothing: 1.
    lambda_rgb_tv: 1.
    lambda_depth_tv: 10.
    lambda_normal_tv: 10.
    lambda_opacity_binary: 10.
    lambda_opacity_max: 1.
    lambda_sugar_density_reg: 0
    lambda_sugar_sdf_normal_reg: 0

    # DreamCraft3D
    lambda_vsd: 0.1
    lambda_lora: 1.
    # lambda_pretrain: 0.1

  optimizer:
    name: AdamW
    args:
      lr: 0.01
      betas: [0.9, 0.99]
      eps: 1.e-8
    params:
      background:
        lr: 0.001
      guidance:
        lr: 0.0001


trainer:
  max_steps: 5000
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  val_check_interval: 100
  enable_progress_bar: true
  precision: 32
  gradient_clip_val: 1.0
  # strategy: "ddp_find_unused_parameters_true"

checkpoint:
  save_last: true # save at each validation time
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}
